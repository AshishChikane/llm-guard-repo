# Toxicity Scanner

It is designed to assess the toxicity level of the content generated by language models, acting as a safeguard against
potentially harmful or offensive output.

## Attack

Language models, when interacting with users, can sometimes produce responses that may be deemed toxic or inappropriate.
This poses a risk, as such output can perpetuate harm or misinformation. By monitoring and classifying the model's
output, potential toxic content can be flagged and handled appropriately.

## How it works

The scanner employs the [unitary/unbiased-toxic-roberta](https://huggingface.co/unitary/unbiased-toxic-roberta) from
HuggingFace to evaluate the generated text's toxicity level.

## Usage

```python
from llm_guard.output_scanners import Toxicity

scanner = Toxicity(threshold=0.7)
sanitized_output, is_valid, risk_score = scanner.scan(prompt, model_output)
```

## Optimizations

### ONNX

The scanner can be optimized by converting the model to ONNX format. This can be done by setting the `use_onnx`.

To enable it, install the `onnxruntime` package:

```sh
pip install llm-guard[onnxruntime]
```

## Benchmarks

Environment:

- Platform: Amazon Linux 2
- Python Version: 3.11.6

Run the following script:

```sh
python benchmarks/run.py output Toxicity
```

Results:

| Instance                     | Input Length | Test Times | Latency Variance | Latency 90 Percentile | Latency 95 Percentile | Latency 99 Percentile | Average Latency (ms) | QPS      |
|------------------------------|--------------|------------|------------------|-----------------------|-----------------------|-----------------------|----------------------|----------|
| AWS m5.xlarge                | 217          | 5          | 2.89             | 154.18                | 181.05                | 202.55                | 100.40               | 2161.43  |
| AWS m5.xlarge with ONNX      | 217          | 5          | 0.00             | 51.64                 | 51.93                 | 52.15                 | 50.95                | 4259.33  |
| AWS g5.xlarge                | 217          | 5          | 33.35            | 282.36                | 373.59                | 446.56                | 99.57                | 2179.37  |
