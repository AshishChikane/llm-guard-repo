{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Loading models from disk\n",
    "\n",
    "In this notebook, we will load the models from disk instead of pulling from HuggingFace. This is helpful when you want to deploy LLM Guard on a server and share the models with other instances."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8760c8003fd2188"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pull models from HuggingFace\n",
    "\n",
    "First, we will pull the models from [HuggingFace and save them to disk](https://huggingface.co/docs/hub/en/models-downloading). You can also pull them from other sources and save them to disk."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e6f396e2630979d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Git LFS initialized.\r\n",
      "fatal: destination path 'deberta-v3-base-prompt-injection' already exists and is not an empty directory.\r\n",
      "fatal: destination path 'deberta-v3-base-zeroshot-v1.1-all-33' already exists and is not an empty directory.\r\n",
      "Cloning into 'span-marker-bert-base-orgs'...\r\n",
      "remote: Enumerating objects: 54, done.\u001B[K\r\n",
      "remote: Total 54 (delta 0), reused 0 (delta 0), pack-reused 54\u001B[K\r\n",
      "Receiving objects: 100% (54/54), 315.67 KiB | 1.40 MiB/s, done.\r\n",
      "Resolving deltas: 100% (14/14), done.\r\n",
      "Updating files: 100% (18/18), done.\r\n",
      "Filtering content: 100% (7/7), 413.35 MiB | 5.22 MiB/s, done.\r\n",
      "Cloning into 'unbiased-toxic-roberta'...\r\n",
      "remote: Enumerating objects: 40, done.\u001B[K\r\n",
      "remote: Total 40 (delta 0), reused 0 (delta 0), pack-reused 40\u001B[K\r\n",
      "Receiving objects: 100% (40/40), 542.30 KiB | 1.58 MiB/s, done.\r\n",
      "Resolving deltas: 100% (18/18), done.\r\n",
      "Updating files: 100% (9/9), done.\r\n",
      "Filtering content: 100% (2/2), 951.16 MiB | 5.48 MiB/s, done.\r\n",
      "Cloning into 'programming-language-identification'...\r\n",
      "remote: Enumerating objects: 67, done.\u001B[K\r\n",
      "remote: Counting objects: 100% (63/63), done.\u001B[K\r\n",
      "remote: Compressing objects: 100% (63/63), done.\u001B[K\r\n",
      "remote: Total 67 (delta 32), reused 0 (delta 0), pack-reused 4\u001B[K\r\n",
      "Receiving objects: 100% (67/67), 1.20 MiB | 2.58 MiB/s, done.\r\n",
      "Resolving deltas: 100% (32/32), done.\r\n",
      "Updating files: 100% (17/17), done.\r\n",
      "Filtering content: 100% (3/3), 636.99 MiB | 5.33 MiB/s, done.\r\n",
      "Cloning into 'autonlp-Gibberish-Detector-492513457'...\r\n",
      "remote: Enumerating objects: 37, done.\u001B[K\r\n",
      "remote: Counting objects: 100% (15/15), done.\u001B[K\r\n",
      "remote: Compressing objects: 100% (15/15), done.\u001B[K\r\n",
      "remote: Total 37 (delta 3), reused 0 (delta 0), pack-reused 22\u001B[K\r\n",
      "Receiving objects: 100% (37/37), 510.13 KiB | 1.48 MiB/s, done.\r\n",
      "Resolving deltas: 100% (9/9), done.\r\n",
      "Updating files: 100% (16/16), done.\r\n",
      "Filtering content: 100% (4/4), 766.44 MiB | 5.36 MiB/s, done.\r\n",
      "Cloning into 'xlm-roberta-base-language-detection'...\r\n",
      "remote: Enumerating objects: 48, done.\u001B[K\r\n",
      "remote: Total 48 (delta 0), reused 0 (delta 0), pack-reused 48\u001B[K\r\n",
      "Receiving objects: 100% (48/48), 3.39 MiB | 1.45 MiB/s, done.\r\n",
      "Resolving deltas: 100% (22/22), done.\r\n",
      "Updating files: 100% (10/10), done.\r\n",
      "Filtering content: 100% (4/4), 3.11 GiB | 5.39 MiB/s, done.\r\n",
      "Cloning into 'deberta-v3-base_finetuned_ai4privacy_v2'...\r\n",
      "remote: Enumerating objects: 158, done.\u001B[K\r\n",
      "remote: Total 158 (delta 0), reused 0 (delta 0), pack-reused 158\u001B[K\r\n",
      "Receiving objects: 100% (158/158), 2.18 MiB | 3.70 MiB/s, done.\r\n",
      "Resolving deltas: 100% (56/56), done.\r\n",
      "Updating files: 100% (21/21), done.\r\n",
      "Filtering content: 100% (5/5), 1.37 GiB | 5.35 MiB/s, done.\r\n"
     ]
    }
   ],
   "source": [
    "!git lfs install\n",
    "!git clone git@hf.co:protectai/deberta-v3-base-prompt-injection\n",
    "!git clone git@hf.co:MoritzLaurer/deberta-v3-base-zeroshot-v1.1-all-33\n",
    "!git clone git@hf.co:tomaarsen/span-marker-bert-base-orgs\n",
    "!git clone git@hf.co:unitary/unbiased-toxic-roberta\n",
    "!git clone git@hf.co:philomath-1209/programming-language-identification\n",
    "!git clone git@hf.co:madhurjindal/autonlp-Gibberish-Detector-492513457\n",
    "!git clone git@hf.co:papluca/xlm-roberta-base-language-detection\n",
    "!git clone git@hf.co:Isotonic/deberta-v3-base_finetuned_ai4privacy_v2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T10:56:55.181551Z",
     "start_time": "2024-02-28T10:33:37.883562Z"
    }
   },
   "id": "8fd2ad9432d5d1cd",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Use local models in LLM Guard\n",
    "\n",
    "Now, we will use the local models in LLM Guard."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1032ae1e578d87a9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!pip install llm_guard@git+https://github.com/protectai/llm-guard.git"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5225102a4ad1007",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m2024-02-28 11:56:55\u001B[0m [\u001B[32m\u001B[1mdebug    \u001B[0m] \u001B[1mNo entity types provided, using default\u001B[0m \u001B[36mdefault_entities\u001B[0m=\u001B[35m['CREDIT_CARD', 'CRYPTO', 'EMAIL_ADDRESS', 'IBAN_CODE', 'IP_ADDRESS', 'PERSON', 'PHONE_NUMBER', 'US_SSN', 'US_BANK_NUMBER', 'CREDIT_CARD_RE', 'UUID', 'EMAIL_ADDRESS_RE', 'US_SSN_RE']\u001B[0m\n",
      "\u001B[2m2024-02-28 11:56:56\u001B[0m [\u001B[32m\u001B[1mdebug    \u001B[0m] \u001B[1mInitialized NER model         \u001B[0m \u001B[36mdevice\u001B[0m=\u001B[35mdevice(type='mps')\u001B[0m \u001B[36mmodel\u001B[0m=\u001B[35mIsotonic/deberta-v3-base_finetuned_ai4privacy_v2\u001B[0m\n",
      "\u001B[2m2024-02-28 11:56:56\u001B[0m [\u001B[32m\u001B[1mdebug    \u001B[0m] \u001B[1mLoaded regex pattern          \u001B[0m \u001B[36mgroup_name\u001B[0m=\u001B[35mCREDIT_CARD_RE\u001B[0m\n",
      "\u001B[2m2024-02-28 11:56:56\u001B[0m [\u001B[32m\u001B[1mdebug    \u001B[0m] \u001B[1mLoaded regex pattern          \u001B[0m \u001B[36mgroup_name\u001B[0m=\u001B[35mUUID\u001B[0m\n",
      "\u001B[2m2024-02-28 11:56:56\u001B[0m [\u001B[32m\u001B[1mdebug    \u001B[0m] \u001B[1mLoaded regex pattern          \u001B[0m \u001B[36mgroup_name\u001B[0m=\u001B[35mEMAIL_ADDRESS_RE\u001B[0m\n",
      "\u001B[2m2024-02-28 11:56:56\u001B[0m [\u001B[32m\u001B[1mdebug    \u001B[0m] \u001B[1mLoaded regex pattern          \u001B[0m \u001B[36mgroup_name\u001B[0m=\u001B[35mUS_SSN_RE\u001B[0m\n",
      "\u001B[2m2024-02-28 11:56:56\u001B[0m [\u001B[32m\u001B[1mdebug    \u001B[0m] \u001B[1mLoaded regex pattern          \u001B[0m \u001B[36mgroup_name\u001B[0m=\u001B[35mBTC_ADDRESS\u001B[0m\n",
      "\u001B[2m2024-02-28 11:56:56\u001B[0m [\u001B[32m\u001B[1mdebug    \u001B[0m] \u001B[1mLoaded regex pattern          \u001B[0m \u001B[36mgroup_name\u001B[0m=\u001B[35mURL_RE\u001B[0m\n",
      "\u001B[2m2024-02-28 11:56:56\u001B[0m [\u001B[32m\u001B[1mdebug    \u001B[0m] \u001B[1mLoaded regex pattern          \u001B[0m \u001B[36mgroup_name\u001B[0m=\u001B[35mCREDIT_CARD\u001B[0m\n",
      "\u001B[2m2024-02-28 11:56:56\u001B[0m [\u001B[32m\u001B[1mdebug    \u001B[0m] \u001B[1mLoaded regex pattern          \u001B[0m \u001B[36mgroup_name\u001B[0m=\u001B[35mEMAIL_ADDRESS_RE\u001B[0m\n",
      "\u001B[2m2024-02-28 11:56:56\u001B[0m [\u001B[32m\u001B[1mdebug    \u001B[0m] \u001B[1mLoaded regex pattern          \u001B[0m \u001B[36mgroup_name\u001B[0m=\u001B[35mPHONE_NUMBER_ZH\u001B[0m\n",
      "\u001B[2m2024-02-28 11:56:56\u001B[0m [\u001B[32m\u001B[1mdebug    \u001B[0m] \u001B[1mLoaded regex pattern          \u001B[0m \u001B[36mgroup_name\u001B[0m=\u001B[35mPHONE_NUMBER_WITH_EXT\u001B[0m\n",
      "\u001B[2m2024-02-28 11:56:56\u001B[0m [\u001B[32m\u001B[1mdebug    \u001B[0m] \u001B[1mLoaded regex pattern          \u001B[0m \u001B[36mgroup_name\u001B[0m=\u001B[35mDATE_RE\u001B[0m\n",
      "\u001B[2m2024-02-28 11:56:56\u001B[0m [\u001B[32m\u001B[1mdebug    \u001B[0m] \u001B[1mLoaded regex pattern          \u001B[0m \u001B[36mgroup_name\u001B[0m=\u001B[35mTIME_RE\u001B[0m\n",
      "\u001B[2m2024-02-28 11:56:56\u001B[0m [\u001B[32m\u001B[1mdebug    \u001B[0m] \u001B[1mLoaded regex pattern          \u001B[0m \u001B[36mgroup_name\u001B[0m=\u001B[35mHEX_COLOR\u001B[0m\n",
      "\u001B[2m2024-02-28 11:56:56\u001B[0m [\u001B[32m\u001B[1mdebug    \u001B[0m] \u001B[1mLoaded regex pattern          \u001B[0m \u001B[36mgroup_name\u001B[0m=\u001B[35mPRICE_RE\u001B[0m\n",
      "\u001B[2m2024-02-28 11:56:56\u001B[0m [\u001B[32m\u001B[1mdebug    \u001B[0m] \u001B[1mLoaded regex pattern          \u001B[0m \u001B[36mgroup_name\u001B[0m=\u001B[35mPO_BOX_RE\u001B[0m\n",
      "\u001B[2m2024-02-28 11:56:59\u001B[0m [\u001B[32m\u001B[1mdebug    \u001B[0m] \u001B[1mInitialized classification model\u001B[0m \u001B[36mdevice\u001B[0m=\u001B[35mdevice(type='mps')\u001B[0m \u001B[36mmodel\u001B[0m=\u001B[35m./deberta-v3-base-zeroshot-v1.1-all-33\u001B[0m\n",
      "\u001B[2m2024-02-28 11:57:01\u001B[0m [\u001B[32m\u001B[1mdebug    \u001B[0m] \u001B[1mInitialized classification model\u001B[0m \u001B[36mdevice\u001B[0m=\u001B[35mdevice(type='mps')\u001B[0m \u001B[36mmodel\u001B[0m=\u001B[35m./unbiased-toxic-roberta\u001B[0m\n",
      "\u001B[2m2024-02-28 11:57:02\u001B[0m [\u001B[32m\u001B[1mdebug    \u001B[0m] \u001B[1mInitialized classification model\u001B[0m \u001B[36mdevice\u001B[0m=\u001B[35mdevice(type='mps')\u001B[0m \u001B[36mmodel\u001B[0m=\u001B[35m./programming-language-identification\u001B[0m\n",
      "\u001B[2m2024-02-28 11:57:02\u001B[0m [\u001B[32m\u001B[1mdebug    \u001B[0m] \u001B[1mInitialized classification model\u001B[0m \u001B[36mdevice\u001B[0m=\u001B[35mdevice(type='mps')\u001B[0m \u001B[36mmodel\u001B[0m=\u001B[35m./autonlp-Gibberish-Detector-492513457\u001B[0m\n",
      "\u001B[2m2024-02-28 11:57:05\u001B[0m [\u001B[32m\u001B[1mdebug    \u001B[0m] \u001B[1mInitialized classification model\u001B[0m \u001B[36mdevice\u001B[0m=\u001B[35mdevice(type='mps')\u001B[0m \u001B[36mmodel\u001B[0m=\u001B[35m./xlm-roberta-base-language-detection\u001B[0m\n",
      "\u001B[2m2024-02-28 11:57:06\u001B[0m [\u001B[32m\u001B[1mdebug    \u001B[0m] \u001B[1mInitialized classification model\u001B[0m \u001B[36mdevice\u001B[0m=\u001B[35mdevice(type='mps')\u001B[0m \u001B[36mmodel\u001B[0m=\u001B[35m./deberta-v3-base-prompt-injection\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m2024-02-28 11:57:07\u001B[0m [\u001B[32m\u001B[1mdebug    \u001B[0m] \u001B[1mPrompt does not have sensitive data to replace\u001B[0m \u001B[36mrisk_score\u001B[0m=\u001B[35m0.0\u001B[0m\n",
      "\u001B[2m2024-02-28 11:57:07\u001B[0m [\u001B[32m\u001B[1mdebug    \u001B[0m] \u001B[1mScanner completed             \u001B[0m \u001B[36melapsed_time_seconds\u001B[0m=\u001B[35m0.189974\u001B[0m \u001B[36mis_valid\u001B[0m=\u001B[35mTrue\u001B[0m \u001B[36mscanner\u001B[0m=\u001B[35mAnonymize\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m2024-02-28 11:57:07\u001B[0m [\u001B[32m\u001B[1mdebug    \u001B[0m] \u001B[1mNo banned topics detected     \u001B[0m \u001B[36mscores\u001B[0m=\u001B[35m{'religion': 0.5899404287338257, 'politics': 0.4100596308708191}\u001B[0m\n",
      "\u001B[2m2024-02-28 11:57:07\u001B[0m [\u001B[32m\u001B[1mdebug    \u001B[0m] \u001B[1mScanner completed             \u001B[0m \u001B[36melapsed_time_seconds\u001B[0m=\u001B[35m0.60365\u001B[0m \u001B[36mis_valid\u001B[0m=\u001B[35mTrue\u001B[0m \u001B[36mscanner\u001B[0m=\u001B[35mBanTopics\u001B[0m\n",
      "\u001B[2m2024-02-28 11:57:08\u001B[0m [\u001B[32m\u001B[1mdebug    \u001B[0m] \u001B[1mNone of the competitors were detected\u001B[0m\n",
      "\u001B[2m2024-02-28 11:57:08\u001B[0m [\u001B[32m\u001B[1mdebug    \u001B[0m] \u001B[1mScanner completed             \u001B[0m \u001B[36melapsed_time_seconds\u001B[0m=\u001B[35m0.52991\u001B[0m \u001B[36mis_valid\u001B[0m=\u001B[35mTrue\u001B[0m \u001B[36mscanner\u001B[0m=\u001B[35mBanCompetitors\u001B[0m\n",
      "\u001B[2m2024-02-28 11:57:08\u001B[0m [\u001B[32m\u001B[1mdebug    \u001B[0m] \u001B[1mNot toxicity found in the text\u001B[0m \u001B[36mresults\u001B[0m=\u001B[35m[[{'label': 'toxicity', 'score': 0.0003712967736646533}, {'label': 'male', 'score': 0.00016587311984039843}, {'label': 'female', 'score': 0.00012892877566628158}, {'label': 'insult', 'score': 0.00011079442629124969}, {'label': 'christian', 'score': 0.0001087861746782437}, {'label': 'psychiatric_or_mental_illness', 'score': 9.981756011256948e-05}, {'label': 'muslim', 'score': 7.031546556390822e-05}, {'label': 'white', 'score': 4.716941839433275e-05}, {'label': 'jewish', 'score': 3.9232210838235915e-05}, {'label': 'identity_attack', 'score': 2.9348657335503958e-05}, {'label': 'homosexual_gay_or_lesbian', 'score': 2.922919338743668e-05}, {'label': 'threat', 'score': 2.9109109163982794e-05}, {'label': 'black', 'score': 2.897163540183101e-05}, {'label': 'obscene', 'score': 2.86914873868227e-05}, {'label': 'sexual_explicit', 'score': 1.7762333300197497e-05}, {'label': 'severe_toxicity', 'score': 1.1558224741747836e-06}]]\u001B[0m\n",
      "\u001B[2m2024-02-28 11:57:08\u001B[0m [\u001B[32m\u001B[1mdebug    \u001B[0m] \u001B[1mScanner completed             \u001B[0m \u001B[36melapsed_time_seconds\u001B[0m=\u001B[35m0.156115\u001B[0m \u001B[36mis_valid\u001B[0m=\u001B[35mTrue\u001B[0m \u001B[36mscanner\u001B[0m=\u001B[35mToxicity\u001B[0m\n",
      "\u001B[2m2024-02-28 11:57:08\u001B[0m [\u001B[32m\u001B[1mdebug    \u001B[0m] \u001B[1mNo Markdown code blocks found in the output\u001B[0m\n",
      "\u001B[2m2024-02-28 11:57:08\u001B[0m [\u001B[32m\u001B[1mdebug    \u001B[0m] \u001B[1mScanner completed             \u001B[0m \u001B[36melapsed_time_seconds\u001B[0m=\u001B[35m0.00025\u001B[0m \u001B[36mis_valid\u001B[0m=\u001B[35mTrue\u001B[0m \u001B[36mscanner\u001B[0m=\u001B[35mCode\u001B[0m\n",
      "\u001B[2m2024-02-28 11:57:08\u001B[0m [\u001B[32m\u001B[1mdebug    \u001B[0m] \u001B[1mGibberish detection finished  \u001B[0m \u001B[36mresults\u001B[0m=\u001B[35m[{'label': 'clean', 'score': 0.4235343933105469}]\u001B[0m\n",
      "\u001B[2m2024-02-28 11:57:08\u001B[0m [\u001B[32m\u001B[1mdebug    \u001B[0m] \u001B[1mNo gibberish in the text      \u001B[0m \u001B[36mhighest_score\u001B[0m=\u001B[35m0.58\u001B[0m \u001B[36mthreshold\u001B[0m=\u001B[35m0.7\u001B[0m\n",
      "\u001B[2m2024-02-28 11:57:08\u001B[0m [\u001B[32m\u001B[1mdebug    \u001B[0m] \u001B[1mScanner completed             \u001B[0m \u001B[36melapsed_time_seconds\u001B[0m=\u001B[35m0.053094\u001B[0m \u001B[36mis_valid\u001B[0m=\u001B[35mTrue\u001B[0m \u001B[36mscanner\u001B[0m=\u001B[35mGibberish\u001B[0m\n",
      "\u001B[2m2024-02-28 11:57:08\u001B[0m [\u001B[32m\u001B[1mdebug    \u001B[0m] \u001B[1mOnly valid languages are found in the text.\u001B[0m\n",
      "\u001B[2m2024-02-28 11:57:08\u001B[0m [\u001B[32m\u001B[1mdebug    \u001B[0m] \u001B[1mScanner completed             \u001B[0m \u001B[36melapsed_time_seconds\u001B[0m=\u001B[35m0.077857\u001B[0m \u001B[36mis_valid\u001B[0m=\u001B[35mTrue\u001B[0m \u001B[36mscanner\u001B[0m=\u001B[35mLanguage\u001B[0m\n",
      "\u001B[2m2024-02-28 11:57:08\u001B[0m [\u001B[32m\u001B[1mdebug    \u001B[0m] \u001B[1mNo prompt injection detected  \u001B[0m \u001B[36mhighest_score\u001B[0m=\u001B[35m0.01\u001B[0m\n",
      "\u001B[2m2024-02-28 11:57:08\u001B[0m [\u001B[32m\u001B[1mdebug    \u001B[0m] \u001B[1mScanner completed             \u001B[0m \u001B[36melapsed_time_seconds\u001B[0m=\u001B[35m0.043963\u001B[0m \u001B[36mis_valid\u001B[0m=\u001B[35mTrue\u001B[0m \u001B[36mscanner\u001B[0m=\u001B[35mPromptInjection\u001B[0m\n",
      "\u001B[2m2024-02-28 11:57:08\u001B[0m [\u001B[32m\u001B[1minfo     \u001B[0m] \u001B[1mScanned prompt                \u001B[0m \u001B[36melapsed_time_seconds\u001B[0m=\u001B[35m1.656615\u001B[0m \u001B[36mscores\u001B[0m=\u001B[35m{'Anonymize': 0.0, 'BanTopics': 0.0, 'BanCompetitors': 0.0, 'Toxicity': 0.0, 'Code': 0.0, 'Gibberish': 0.0, 'Language': 0.0, 'PromptInjection': 0.0}\u001B[0m\n",
      "I am happy\n",
      "{'Anonymize': True, 'BanTopics': True, 'BanCompetitors': True, 'Toxicity': True, 'Code': True, 'Gibberish': True, 'Language': True, 'PromptInjection': True}\n",
      "{'Anonymize': 0.0, 'BanTopics': 0.0, 'BanCompetitors': 0.0, 'Toxicity': 0.0, 'Code': 0.0, 'Gibberish': 0.0, 'Language': 0.0, 'PromptInjection': 0.0}\n"
     ]
    }
   ],
   "source": [
    "from llm_guard import scan_prompt\n",
    "from llm_guard.input_scanners import PromptInjection, Anonymize, BanTopics, BanCompetitors, Toxicity, Code, Gibberish, Language\n",
    "from llm_guard.vault import Vault\n",
    "from llm_guard.input_scanners.prompt_injection import MODEL_LAIYER as PROMPT_INJECTION_MODEL\n",
    "from llm_guard.input_scanners.anonymize_helpers import DEBERTA_AI4PRIVACY_v2_CONF\n",
    "\n",
    "PROMPT_INJECTION_MODEL[\"path\"] = \"./deberta-v3-base-prompt-injection\"\n",
    "DEBERTA_AI4PRIVACY_v2_CONF[\"path\"] = \"./deberta-v3-base_finetuned_ai4privacy_v2\"\n",
    "DEBERTA_AI4PRIVACY_v2_CONF[\"ONNX_MODEL_PATH\"] = \"./deberta-v3-base_finetuned_ai4privacy_v2\"\n",
    "\n",
    "vault = Vault()\n",
    "input_scanners = [\n",
    "    Anonymize(vault, model_kwargs={\"local_files_only\": True}, recognizer_conf=DEBERTA_AI4PRIVACY_v2_CONF),\n",
    "    BanTopics([\"politics\", \"religion\"], model=\"./deberta-v3-base-zeroshot-v1.1-all-33\", model_kwargs={\"local_files_only\": True}),\n",
    "    BanCompetitors([\"google\", \"facebook\"], model=\"./span-marker-bert-base-orgs\", model_kwargs={\"local_files_only\": True}),\n",
    "    Toxicity(model_path=\"./unbiased-toxic-roberta\", model_kwargs={\"local_files_only\": True}),\n",
    "    Code([\"Python\", \"PHP\"], model_path=\"./programming-language-identification\", model_kwargs={\"local_files_only\": True}),\n",
    "    Gibberish(model_path=\"./autonlp-Gibberish-Detector-492513457\", model_kwargs={\"local_files_only\": True}),\n",
    "    Language([\"en\"], model_path=\"./xlm-roberta-base-language-detection\", model_kwargs={\"local_files_only\": True}),\n",
    "    PromptInjection(model_kwargs={\"local_files_only\": True}, model=PROMPT_INJECTION_MODEL)\n",
    "]\n",
    "\n",
    "sanitized_prompt, results_valid, results_score = scan_prompt(\n",
    "    input_scanners,\n",
    "    \"I am happy\",\n",
    ")\n",
    "\n",
    "print(sanitized_prompt)\n",
    "print(results_valid)\n",
    "print(results_score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T10:57:08.675369Z",
     "start_time": "2024-02-28T10:56:55.185189Z"
    }
   },
   "id": "5bdbb7744e414c5d",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c4d075bc6d663d22"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
